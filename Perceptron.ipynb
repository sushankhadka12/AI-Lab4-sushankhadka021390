{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0UqNEovgp1T7FTbz6e+gT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushankhadka12/AI-Lab4-sushankhadka021390/blob/main/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idz4alsPmJDO",
        "outputId": "e47c3eb4-31b0-44a3-d88e-257a92a1d3ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 2-Input Basic Gates (AND/OR)\n",
            "2. n-Input Basic Gates (AND/OR)\n",
            "3. Linear Function with 3 Features\n",
            "4. Linear Function with n Features\n",
            "Select option: 1\n",
            "\n",
            "Training AND Gate:\n",
            "Epoch 1: Weights = [0.05241957 0.56547077], Bias = 0.31097809250751973, Accuracy = 25.0%\n",
            "Epoch 2: Weights = [-0.04758043  0.46547077], Bias = 0.010978092507519716, Accuracy = 25.0%\n",
            "Epoch 3: Weights = [-0.04758043  0.36547077], Bias = -0.1890219074924803, Accuracy = 50.0%\n",
            "Epoch 4: Weights = [0.05241957 0.36547077], Bias = -0.1890219074924803, Accuracy = 50.0%\n",
            "Epoch 5: Weights = [0.05241957 0.26547077], Bias = -0.2890219074924803, Accuracy = 75.0%\n",
            "Epoch 6: Weights = [0.05241957 0.26547077], Bias = -0.2890219074924803, Accuracy = 100.0%\n",
            "Converged!\n",
            "\n",
            "Final AND Gate Parameters:\n",
            "Weights: [0.05241957 0.26547077], Bias: -0.2890219074924803\n",
            "\n",
            "Training OR Gate:\n",
            "Epoch 1: Weights = [0.77992172 0.46284358], Bias = 0.6912555204004668, Accuracy = 75.0%\n",
            "Epoch 2: Weights = [0.77992172 0.46284358], Bias = 0.5912555204004668, Accuracy = 75.0%\n",
            "Epoch 3: Weights = [0.77992172 0.46284358], Bias = 0.4912555204004668, Accuracy = 75.0%\n",
            "Epoch 4: Weights = [0.77992172 0.46284358], Bias = 0.39125552040046685, Accuracy = 75.0%\n",
            "Epoch 5: Weights = [0.77992172 0.46284358], Bias = 0.29125552040046687, Accuracy = 75.0%\n",
            "Epoch 6: Weights = [0.77992172 0.46284358], Bias = 0.19125552040046687, Accuracy = 75.0%\n",
            "Epoch 7: Weights = [0.77992172 0.46284358], Bias = 0.09125552040046686, Accuracy = 75.0%\n",
            "Epoch 8: Weights = [0.77992172 0.46284358], Bias = -0.008744479599533145, Accuracy = 75.0%\n",
            "Epoch 9: Weights = [0.77992172 0.46284358], Bias = -0.008744479599533145, Accuracy = 100.0%\n",
            "Converged!\n",
            "\n",
            "Final OR Gate Parameters:\n",
            "Weights: [0.77992172 0.46284358], Bias: -0.008744479599533145\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, activation='step'):\n",
        "        self.weights = np.random.rand(input_size)\n",
        "        self.bias = np.random.rand()\n",
        "        self.activation = activation\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        summation = np.dot(inputs, self.weights) + self.bias\n",
        "        if self.activation == 'step':\n",
        "            return 1 if summation >= 0 else 0\n",
        "        else:\n",
        "            return summation\n",
        "\n",
        "    def train(self, training_data, labels, learning_rate=0.1, epochs=100, task_type='classification'):\n",
        "        history = []\n",
        "        for epoch in range(epochs):\n",
        "            if task_type == 'classification':\n",
        "                total_error = 0\n",
        "                correct = 0\n",
        "                for inputs, label in zip(training_data, labels):\n",
        "                    prediction = self.predict(inputs)\n",
        "                    error = label - prediction\n",
        "                    total_error += abs(error)\n",
        "                    if error == 0:\n",
        "                        correct += 1\n",
        "                    self.weights += learning_rate * error * inputs\n",
        "                    self.bias += learning_rate * error\n",
        "                accuracy = correct / len(labels) * 100\n",
        "                history.append(accuracy)\n",
        "                print(f\"Epoch {epoch + 1}: Weights = {self.weights}, Bias = {self.bias}, Accuracy = {accuracy}%\")\n",
        "                if total_error == 0:\n",
        "                    print(\"Converged!\")\n",
        "                    break\n",
        "            else:\n",
        "                predictions = np.array([self.predict(x) for x in training_data])\n",
        "                errors = labels - predictions\n",
        "                mse = np.mean(errors**2)\n",
        "                history.append(mse)\n",
        "                self.weights += learning_rate * np.dot(training_data.T, errors) / len(labels)\n",
        "                self.bias += learning_rate * np.sum(errors) / len(labels)\n",
        "                print(f\"Epoch {epoch + 1}: MSE = {mse:.4f}\")\n",
        "        return history\n",
        "\n",
        "def generate_truth_table(n, gate_type):\n",
        "    inputs = []\n",
        "    labels = []\n",
        "    for i in range(2**n):\n",
        "        binary = format(i, f'0{n}b')\n",
        "        input_vec = [int(bit) for bit in binary]\n",
        "        inputs.append(input_vec)\n",
        "        if gate_type == 'AND':\n",
        "            labels.append(1 if all(input_vec) else 0)\n",
        "        elif gate_type == 'OR':\n",
        "            labels.append(1 if any(input_vec) else 0)\n",
        "    return np.array(inputs), np.array(labels)\n",
        "\n",
        "def generate_linear_data(n_features, true_weights, true_bias, n_samples=10):\n",
        "    X = np.random.rand(n_samples, n_features)\n",
        "    y = np.dot(X, true_weights) + true_bias\n",
        "    return X, y\n",
        "\n",
        "def run_2input_gates():\n",
        "    and_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "    and_labels = np.array([0, 0, 0, 1])\n",
        "    or_labels = np.array([0, 1, 1, 1])\n",
        "\n",
        "    print(\"\\nTraining AND Gate:\")\n",
        "    and_perceptron = Perceptron(input_size=2)\n",
        "    and_perceptron.train(and_data, and_labels)\n",
        "    print(f\"\\nFinal AND Gate Parameters:\\nWeights: {and_perceptron.weights}, Bias: {and_perceptron.bias}\")\n",
        "\n",
        "    print(\"\\nTraining OR Gate:\")\n",
        "    or_perceptron = Perceptron(input_size=2)\n",
        "    or_perceptron.train(and_data, or_labels)\n",
        "    print(f\"\\nFinal OR Gate Parameters:\\nWeights: {or_perceptron.weights}, Bias: {or_perceptron.bias}\")\n",
        "\n",
        "def run_ninput_gates(n):\n",
        "    print(f\"\\nTraining {n}-input AND Gate:\")\n",
        "    and_data, and_labels = generate_truth_table(n, 'AND')\n",
        "    and_perceptron = Perceptron(input_size=n)\n",
        "    and_perceptron.train(and_data, and_labels)\n",
        "    print(f\"\\nFinal {n}-input AND Gate Parameters:\\nWeights: {and_perceptron.weights}, Bias: {and_perceptron.bias}\")\n",
        "\n",
        "    print(f\"\\nTraining {n}-input OR Gate:\")\n",
        "    or_data, or_labels = generate_truth_table(n, 'OR')\n",
        "    or_perceptron = Perceptron(input_size=n)\n",
        "    or_perceptron.train(or_data, or_labels)\n",
        "    print(f\"\\nFinal {n}-input OR Gate Parameters:\\nWeights: {or_perceptron.weights}, Bias: {or_perceptron.bias}\")\n",
        "\n",
        "def run_linear_3features():\n",
        "    true_weights = np.array([2, 3, -1])\n",
        "    true_bias = 5\n",
        "    X, y = generate_linear_data(3, true_weights, true_bias)\n",
        "\n",
        "    print(\"\\nTraining Linear Perceptron (3 features):\")\n",
        "    linear_perceptron = Perceptron(input_size=3, activation='linear')\n",
        "    linear_perceptron.train(X, y, learning_rate=0.01, task_type='regression')\n",
        "    print(f\"\\nFinal Linear Perceptron Parameters:\\nWeights: {linear_perceptron.weights}\\nBias: {linear_perceptron.bias}\")\n",
        "    print(f\"True function: y = 2x₁ + 3x₂ - x₃ + 5\")\n",
        "\n",
        "def run_linear_nfeatures(n):\n",
        "    true_weights = np.random.randint(-5, 6, size=n)\n",
        "    true_bias = np.random.randint(-5, 6)\n",
        "    X, y = generate_linear_data(n, true_weights, true_bias)\n",
        "\n",
        "    print(f\"\\nTrue function: y = {true_weights[0]}x₁\", end=\"\")\n",
        "    for i in range(1, n):\n",
        "        print(f\" + {true_weights[i]}x_{i+1}\", end=\"\")\n",
        "    print(f\" + {true_bias}\")\n",
        "\n",
        "    print(f\"\\nTraining Linear Perceptron ({n} features):\")\n",
        "    linear_perceptron = Perceptron(input_size=n, activation='linear')\n",
        "    linear_perceptron.train(X, y, learning_rate=0.01, task_type='regression')\n",
        "    print(f\"\\nFinal Linear Perceptron Parameters:\\nWeights: {linear_perceptron.weights}\\nBias: {linear_perceptron.bias}\")\n",
        "\n",
        "def main():\n",
        "    print(\"1. 2-Input Basic Gates (AND/OR)\")\n",
        "    print(\"2. n-Input Basic Gates (AND/OR)\")\n",
        "    print(\"3. Linear Function with 3 Features\")\n",
        "    print(\"4. Linear Function with n Features\")\n",
        "    choice = int(input(\"Select option: \"))\n",
        "\n",
        "    if choice == 1:\n",
        "        run_2input_gates()\n",
        "    elif choice == 2:\n",
        "        n = int(input(\"Enter number of inputs (n): \"))\n",
        "        run_ninput_gates(n)\n",
        "    elif choice == 3:\n",
        "        run_linear_3features()\n",
        "    elif choice == 4:\n",
        "        n = int(input(\"Enter number of features (n): \"))\n",
        "        run_linear_nfeatures(n)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}